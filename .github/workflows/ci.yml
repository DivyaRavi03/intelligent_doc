# =============================================================================
# CI/CD Pipeline — Intelligent Document Processing Platform
#
# Triggers on push to main:
#   1. Lint (ruff) + Type check (mypy) + Unit tests (pytest) — in parallel
#   2. Integration tests — after lint/typecheck/unit pass
#   3. Evaluation benchmark — after integration tests (main only)
#   4. Build & push Docker image to Artifact Registry — after integration tests (main only)
#   5. Deploy to Cloud Run — after image push (main only)
# =============================================================================

name: CI/CD Pipeline

on:
  push:
    branches: [main]

permissions:
  contents: read

env:
  PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
  REGION: us-central1
  SERVICE_NAME: research-processor
  IMAGE: us-central1-docker.pkg.dev/${{ secrets.GCP_PROJECT_ID }}/research-processor/research-processor

jobs:
  # -------------------------------------------------------------------------
  # Stage 1: Quality checks (run in parallel)
  # -------------------------------------------------------------------------

  lint:
    name: Lint
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - run: pip install ruff
      - run: ruff check src/

  type-check:
    name: Type Check
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - run: pip install -e ".[dev]"
      - run: mypy src/

  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - run: pip install -e ".[dev]"
      - run: pytest tests/unit/ -v --cov=src --cov-report=xml --cov-report=term
      - uses: actions/upload-artifact@v4
        with:
          name: coverage-report
          path: coverage.xml

  # -------------------------------------------------------------------------
  # Stage 2: Integration tests (after quality checks pass)
  # -------------------------------------------------------------------------

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [lint, type-check, unit-tests]
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - run: pip install -e ".[dev]"
      - name: Start backing services
        run: docker compose -f docker-compose.yml up -d postgres redis
      - name: Wait for services to be healthy
        run: |
          for i in $(seq 1 30); do
            docker compose -f docker-compose.yml exec -T postgres pg_isready -U docuser && break
            sleep 2
          done
      - run: pytest tests/integration/ -v
      - name: Tear down services
        if: always()
        run: docker compose -f docker-compose.yml down

  # -------------------------------------------------------------------------
  # Stage 3: Evaluation benchmark (main only, after integration)
  # -------------------------------------------------------------------------

  evaluation:
    name: Evaluation Benchmark
    runs-on: ubuntu-latest
    needs: [integration-tests]
    if: github.ref == 'refs/heads/main'
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - run: pip install -e .
      - name: Run evaluation benchmark
        run: |
          mkdir -p reports
          python scripts/run_eval.py --output reports/eval.json
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        continue-on-error: true
      - uses: actions/upload-artifact@v4
        with:
          name: eval-report
          path: reports/eval.json
          if-no-files-found: ignore

  # -------------------------------------------------------------------------
  # Stage 4: Build and push Docker image (main only)
  # -------------------------------------------------------------------------

  build-and-push:
    name: Build & Push Docker Image
    runs-on: ubuntu-latest
    needs: [integration-tests]
    if: github.ref == 'refs/heads/main'
    steps:
      - uses: actions/checkout@v4
      - name: Authenticate to GCP
        id: auth
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}
      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2
      - name: Configure Docker for Artifact Registry
        run: gcloud auth configure-docker us-central1-docker.pkg.dev --quiet
      - name: Build Docker image
        run: docker build -t ${{ env.IMAGE }}:${{ github.sha }} -t ${{ env.IMAGE }}:latest .
      - name: Push to Artifact Registry
        run: |
          docker push ${{ env.IMAGE }}:${{ github.sha }}
          docker push ${{ env.IMAGE }}:latest

  # -------------------------------------------------------------------------
  # Stage 5: Deploy to Cloud Run (main only, after image push)
  # -------------------------------------------------------------------------

  deploy:
    name: Deploy to Cloud Run
    runs-on: ubuntu-latest
    needs: [build-and-push]
    if: github.ref == 'refs/heads/main'
    steps:
      - uses: actions/checkout@v4
      - name: Authenticate to GCP
        id: auth
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}
      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2
      - name: Deploy to Cloud Run
        run: |
          gcloud run deploy ${{ env.SERVICE_NAME }} \
            --image ${{ env.IMAGE }}:${{ github.sha }} \
            --region ${{ env.REGION }} \
            --platform managed \
            --memory 2Gi \
            --cpu 2 \
            --min-instances 0 \
            --max-instances 4 \
            --allow-unauthenticated \
            --set-env-vars "PYTHONPATH=/app" \
            --set-secrets "GEMINI_API_KEY=gemini-api-key:latest,DATABASE_URL=database-url:latest" \
            --port 8000
      - name: Print service URL
        run: |
          gcloud run services describe ${{ env.SERVICE_NAME }} \
            --region ${{ env.REGION }} \
            --format "value(status.url)"
